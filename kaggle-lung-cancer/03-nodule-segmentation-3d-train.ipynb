{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train 3d nodule detector with LUNA16 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../../input/nodules/'\n",
    "OUTPUT_DIR = '../../output/lung-cancer/03/'\n",
    "IMAGE_DIMS = (50,50,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.utils as utils\n",
    "from modules.utils import Timer\n",
    "import modules.logging\n",
    "import modules.cnn as cnn\n",
    "import modules.ctscan as ctscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-26 21:30:52,480 INFO Dir ../../output/lung-cancer/03/ created\n"
     ]
    }
   ],
   "source": [
    "utils.mkdirs(OUTPUT_DIR, recreate=True)\n",
    "modules.logging.setup_file_logger(OUTPUT_DIR + 'out.log')\n",
    "logger.info('Dir ' + OUTPUT_DIR + ' created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-26 21:30:53,857 INFO Prepare CNN for training\n",
      "2017-03-26 21:30:53,937 INFO Prepare CNN\n",
      "2017-03-26 21:30:53,938 INFO Preparing output dir\n",
      "2017-03-26 21:30:53,939 INFO Initializing network...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Prepare CNN for training')\n",
    "network = cnn.net_nodule3d_swethasubramanian(IMAGE_DIMS)\n",
    "model = cnn.prepare_cnn_model(network, OUTPUT_DIR, model_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3570  | total loss: \u001b[1m\u001b[32m0.17078\u001b[0m\u001b[0m | time: 571.119s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 052 | loss: 0.17078 - acc: 0.9386 -- iter: 4896/6616\n"
     ]
    }
   ],
   "source": [
    "dataset_path = INPUT_DIR + 'nodules-train.h5'\n",
    "\n",
    "with h5py.File(dataset_path, 'r') as train_hdf5:\n",
    "    X = train_hdf5['X']\n",
    "    Y = train_hdf5['Y']\n",
    "    logger.info('X shape ' + str(X.shape))\n",
    "    logger.info('Y shape ' + str(Y.shape))\n",
    "\n",
    "    dataset_path = INPUT_DIR + 'nodules-validate.h5'\n",
    "    with h5py.File(dataset_path, 'r') as validate_hdf5:\n",
    "        X_validate = validate_hdf5['X']\n",
    "        Y_validate = validate_hdf5['Y']\n",
    "        logger.info('X_validate shape ' + str(X_validate.shape))\n",
    "        logger.info('Y_validate shape ' + str(Y_validate.shape))\n",
    "\n",
    "        logger.info('Starting CNN training...')\n",
    "        model.fit(X, Y, \n",
    "            validation_set=(X_validate, Y_validate), \n",
    "            shuffle=True, \n",
    "            batch_size=96, \n",
    "            n_epoch=100,\n",
    "            show_metric=True,\n",
    "            snapshot_epoch=True,\n",
    "            run_id='nodule_classifier')\n",
    "\n",
    "model.save(OUTPUT_DIR + \"nodule-classifier.tfl\")\n",
    "logger.info(\"Network trained and saved as nodule-classifier.tfl!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logger.info('Evaluate dataset')\n",
    "evaluate_dataset(OUTPUT_DIR + 'nodules-test.h5', model, batch_size=12, confusion_matrix=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
