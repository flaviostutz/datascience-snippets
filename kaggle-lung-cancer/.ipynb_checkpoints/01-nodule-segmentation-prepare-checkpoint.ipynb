{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train nodule detector with LUNA16 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../../input/'\n",
    "OUTPUT_DIR = '../../output/lung-cancer/01/'\n",
    "IMAGE_DIMS = (50,50,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (ImageAugmentation3d.py, line 178)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/notebooks/datascience-snippets/kaggle-lung-cancer/modules/ImageAugmentation3d.py\"\u001b[0;36m, line \u001b[0;32m178\u001b[0m\n\u001b[0;31m    return batch\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.utils as utils\n",
    "from modules.utils import Timer\n",
    "import modules.logging\n",
    "import modules.cnn as cnn\n",
    "import modules.ctscan as ctscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Analyse input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Let us import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(INPUT_DIR + 'annotations.csv')\n",
    "candidates = pd.read_csv(INPUT_DIR + 'candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(annotations.iloc[1]['seriesuid'])\n",
    "print(str(annotations.head()))\n",
    "annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(candidates.iloc[1]['seriesuid'])\n",
    "print(str(candidates.head()))\n",
    "candidates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(candidates[candidates['class'] == 1]))\n",
    "print(len(candidates[candidates['class'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lets take a look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scan = ctscan.CTScanMhd(INPUT_DIR, '1.3.6.1.4.1.14519.5.2.1.6279.6001.979083010707182900091062408058')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pixels = scan.get_image()\n",
    "plt.imshow(pixels[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pixels = scan.get_subimage((40,40,10), (230,230,230))\n",
    "plt.imshow(pixels[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Classes are heaviliy unbalanced, hardly 0.2% percent are positive.\n",
    "\n",
    "The best way to move forward will be to undersample the negative class and then augment the positive class heaviliy to balance out the samples.\n",
    "\n",
    "#### Plan of attack:\n",
    "\n",
    "1. Get an initial subsample of negative class and keep all of the positives such that we have a 80/20 class distribution\n",
    "\n",
    "2. Create a training set such that we augment minority class heavilby rotating to get a 50/50 class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positives = candidates[candidates['class']==1].index  \n",
    "negatives = candidates[candidates['class']==0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Ok the class to get image data works\n",
    "\n",
    "Next thing to do is to undersample negative class drastically. Since the number of positives in the data set of 551065 are 1351 and rest are negatives, I plan to make the dataset less skewed. Like a 70%/30% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "negIndexes = np.random.choice(negatives, len(positives)*5, replace = False)\n",
    "print(len(positives))\n",
    "print(len(negIndexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "candidatesDf = candidates.iloc[list(positives)+list(negIndexes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Split into test train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X = candidatesDf.iloc[:,:-1]\n",
    "Y = candidatesDf.iloc[:,-1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(str(X_test))\n",
    "#print(str(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('number of positive cases are ' + str(Y_train.sum()))\n",
    "print('total set size is ' + str(len(Y_train)))\n",
    "print('percentage of positive cases are ' + str(Y_train.sum()*1.0/len(Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### We will need to augment the positive dataset like mad! Add new keys to X_train and Y_train for augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tempDf = X_train[Y_train == 1]\n",
    "tempDf = tempDf.set_index(X_train[Y_train == 1].index + 1000000)\n",
    "X_train_new = X_train.append(tempDf)\n",
    "tempDf = tempDf.set_index(X_train[Y_train == 1].index + 2000000)\n",
    "X_train_new = X_train_new.append(tempDf)\n",
    "\n",
    "ytemp = Y_train.reindex(X_train[Y_train == 1].index + 1000000)\n",
    "ytemp.loc[:] = 1\n",
    "Y_train_new = Y_train.append(ytemp)\n",
    "ytemp = Y_train.reindex(X_train[Y_train == 1].index + 2000000)\n",
    "ytemp.loc[:] = 1\n",
    "Y_train_new = Y_train_new.append(ytemp)\n",
    "\n",
    "X_train = X_train_new\n",
    "Y_train = Y_train_new\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('After undersampling')\n",
    "print('number of positive cases are ' + str(Y_train.sum()))\n",
    "print('total set size is ' + str(len(Y_train)))\n",
    "print('percentage of positive cases are ' + str(Y_train.sum()*1.0/len(Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "utils.mkdirs(OUTPUT_DIR, recreate=True)\n",
    "modules.logging.setup_file_logger(OUTPUT_DIR + 'out.log')\n",
    "logger.info('Dir ' + OUTPUT_DIR + ' created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create HDF5 dataset with input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(file_path, x_data, y_data):\n",
    "    logger.info('Creating dataset ' + file_path + ' size=' + str(len(x_data)))\n",
    "    file_path_tmp = file_path + '.tmp'\n",
    "    with h5py.File(file_path_tmp, 'w') as h5f:\n",
    "        x_ds = h5f.create_dataset('X', (len(x_data), IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2], IMAGE_DIMS[3]), chunks=(1, IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2], IMAGE_DIMS[3]), dtype='f')\n",
    "        y_ds = h5f.create_dataset('Y', (len(y_data), 2), dtype='f')\n",
    "        valid = []\n",
    "        for c, idx in enumerate(x_data.index):\n",
    "            #if(c>3): break\n",
    "            d = x_data.loc[idx]\n",
    "            filename = d[0]\n",
    "            t = Timer('Loading scan ' + str(filename))\n",
    "            scan = ctscan.CTScanMhd(INPUT_DIR, filename)\n",
    "            pixels = scan.get_subimage((d[3],d[2],d[1]), IMAGE_DIMS)\n",
    "            #add color channel dimension\n",
    "            pixels = np.expand_dims(pixels, axis=3)\n",
    "            #plt.imshow(pixels[round(np.shape(pixels)[0]/2),:,:,0])\n",
    "            #plt.show()\n",
    "            if(np.shape(pixels) == (50,50,50,1)):\n",
    "                x_ds[c] = pixels\n",
    "                y_ds[c] = [1,0]\n",
    "                if(y_data.loc[idx] == 1):\n",
    "                    y_ds[c] = [0,1]\n",
    "                valid.append(c)\n",
    "            else:\n",
    "                logger.warning('Invalid shape detected in image. Skipping. ' + str(np.shape(pixels)))\n",
    "            t.stop()\n",
    "\n",
    "    #dump only valid entries to dataset file\n",
    "    c = 0\n",
    "    with h5py.File(file_path, 'w') as h5fw:\n",
    "        x_dsw = h5fw.create_dataset('X', (len(valid), IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2], IMAGE_DIMS[3]), chunks=(1, IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2], IMAGE_DIMS[3]), dtype='f')\n",
    "        y_dsw = h5fw.create_dataset('Y', (len(valid), 2), dtype='f')\n",
    "        with h5py.File(file_path_tmp, 'r') as h5fr:\n",
    "            x_dsr = h5fr['X']\n",
    "            y_dsr = h5fr['Y']\n",
    "            for i in range(len(x_dsr)):\n",
    "                if(i in valid):\n",
    "                    x_dsw[c] = x_dsr[i]\n",
    "                    y_dsw[c] = y_dsr[i]\n",
    "                    c = c + 1\n",
    "\n",
    "    os.remove(file_path_tmp)\n",
    "            \n",
    "    utils.validate_xy_dataset(file_path, save_dir=OUTPUT_DIR + 'samples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_dataset(OUTPUT_DIR + 'nodules-train.h5', X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_dataset(OUTPUT_DIR + 'nodules-validate.h5', X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_dataset(OUTPUT_DIR + 'nodules-test.h5', X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
