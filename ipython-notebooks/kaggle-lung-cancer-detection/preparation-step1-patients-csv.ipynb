{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get patients image size and mask boundings into CSV\n",
    "* Each script uses only a single GPU, so we will distribute patients among shards in order to distribute or paralellize execution\n",
    "* For each shard, duplicate this script, set a unique SHARD_ID and execute it\n",
    "* This script:\n",
    "   * Creates a directory named \"patients-[shard_id]\" with all its results\n",
    "   * Creates a file \"patients-analysis.csv\" with all imaging analysis data\n",
    "   * Snapshots 3 slides for each patient to directory \"samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only (patient_id%NR_SHARDS) == SHARD_ID will be processed here\n",
    "#choose a value between 1-NR_SHARDS\n",
    "SHARD_ID = 2\n",
    "\n",
    "NR_SHARDS = 4\n",
    "\n",
    "#Patient DICOM images folder\n",
    "INPUT_FOLDER = '../../input/sample_images/'\n",
    "OUTPUT_FOLDER = '../../output/' + str(SHARD_ID) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from numpy import ndarray\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import statistics\n",
    "import csv\n",
    "import dicom\n",
    "from time import time\n",
    "import os\n",
    "import shutil\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.ndimage as ndimage\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "from skimage import measure, morphology\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name, debug=True):\n",
    "        self._name = name\n",
    "        self._debug = debug\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        self._start = time()\n",
    "        if(self._debug):\n",
    "            log('> [started] ' + self._name + '...')\n",
    "\n",
    "    def stop(self):\n",
    "        self._lastElapsed = (time()-self._start)\n",
    "        if(self._debug):\n",
    "            log('> [done]    {} ({:.3f} ms)'.format(self._name, self._lastElapsed*1000))\n",
    "            \n",
    "    def elapsed(self):\n",
    "        if(self._lastElapsed != None):\n",
    "            return (self._lastElapsed)\n",
    "        else:\n",
    "            return (time()-self._start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def log(message):\n",
    "    print('{} {}'.format(datetime.datetime.now(), message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_patient_ids(shard_id, input_folder):\n",
    "  shard_patients = []\n",
    "  patients = os.listdir(input_folder)\n",
    "  patients.sort()\n",
    "  for p in patients:\n",
    "    if(int(p,16)%NR_SHARDS == (shard_id-1)):\n",
    "      shard_patients.append(p)\n",
    "  return shard_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the scans in given folder path\n",
    "#image pixels dimensions: z, y, x\n",
    "def load_scan(path):\n",
    "    t = Timer('load_scan ' + path)\n",
    "    \n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.slice_thickness = slice_thickness\n",
    "\n",
    "    t.stop()\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#image pixels dimensions: z, y, x\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image pixels dimensions: z, y, x\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    t = Timer('resample')\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].slice_thickness] + scan[0].PixelSpacing, dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    t.stop()\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def largest_label_volume(im, bg=-1):\n",
    "    vals, counts = np.unique(im, return_counts=True)\n",
    "\n",
    "    counts = counts[vals != bg]\n",
    "    vals = vals[vals != bg]\n",
    "\n",
    "    if len(counts) > 0:\n",
    "        return vals[np.argmax(counts)]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_lung_mask(image, fill_lung_structures=True):\n",
    "    t = Timer('segment_lung_mask')\n",
    "\n",
    "    # 0 is treated as background, which we do not want\n",
    "    binary_image = np.array(image > -320, dtype=np.int8)+1\n",
    "    labels = measure.label(binary_image)\n",
    "\n",
    "    # Pick the pixel in the very corner to determine which label is air.\n",
    "    #   Improvement: Pick multiple background labels from around the patient\n",
    "    #   More resistant to \"trays\" on which the patient lays cutting the air \n",
    "    #   around the person in half\n",
    "    background_label = labels[0,0,0] \n",
    "    \n",
    "    #Fill the air around the person\n",
    "    binary_image[background_label == labels] = 2\n",
    "\n",
    "    # Method of filling the lung structures (that is superior to something like \n",
    "    # morphological closing)\n",
    "    if fill_lung_structures:\n",
    "        # For every slice we determine the largest solid structure\n",
    "        for i, axial_slice in enumerate(binary_image):\n",
    "            axial_slice = axial_slice - 1\n",
    "            labeling = measure.label(axial_slice)\n",
    "            l_max = largest_label_volume(labeling, bg=0)\n",
    "            \n",
    "            if l_max is not None: #This slice contains some lung\n",
    "                binary_image[i][labeling != l_max] = 1\n",
    "    \n",
    "    binary_image -= 1 #Make the image actual binary\n",
    "    binary_image = 1-binary_image # Invert it, lungs are now 1\n",
    "    \n",
    "    # Remove other air pockets insided body\n",
    "    labels = measure.label(binary_image, background=0)\n",
    "    \n",
    "    l_max = largest_label_volume(labels, bg=0)\n",
    "    if l_max is not None: # There are air pockets\n",
    "        binary_image[labels != l_max] = 0\n",
    "\n",
    "    #dilate mask\n",
    "    binary_image = scipy.ndimage.morphology.grey_dilation(binary_image, size=(10,10,10))\n",
    "    t.stop()\n",
    "    \n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns ((x1, y1, z1), (x2, y2, z2))\n",
    "def bounding_box(img):\n",
    "    N = img.ndim\n",
    "    out = []\n",
    "    for ax in itertools.combinations(range(N), N - 1):\n",
    "        nonzero = np.any(img, axis=ax)\n",
    "        out.extend(np.where(nonzero)[0][[0, -1]])\n",
    "    r = np.reshape(np.asarray(tuple(out)), (-1, 2)).T\n",
    "    return [tuple(r[0]), tuple(r[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#return bounding box center in (x,y,z)\n",
    "def bounding_box_center(bounds):\n",
    "    return (int(round((bounds[0][0] + (bounds[1][0]-bounds[0][0])/2))), int(round((bounds[0][1] + (bounds[1][1]-bounds[0][1])/2))), int(round((bounds[0][2] + (bounds[1][2]-bounds[0][2])/2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_slice_shot(patient_pixels, patient_lung_mask, patient_id, slice_pos, output_dir):\n",
    "    t = Timer('generate_slice_shot ' + str(slice_pos))\n",
    "    fig1, ax1 = plt.subplots(1)\n",
    "    fig1.set_size_inches(6,6)\n",
    "\n",
    "    masked_img = np.ma.masked_where(patient_lung_mask[slice_pos]==0, patient_pixels[slice_pos])\n",
    "    ax1.imshow(masked_img, cmap=plt.cm.gray)\n",
    "\n",
    "    file = output_dir + patient_id + '-' + 'slice-' + str(slice_pos) + '.jpg'\n",
    "    plt.savefig(file)\n",
    "        \n",
    "    plt.close(fig1)\n",
    "#    plt.show()\n",
    "    t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_patient_info(patient_pixels, patient_lung_mask, patient_scan, patient_id, append_to_csv_file):\n",
    "    t = Timer('generate_patient_info')\n",
    "    info = []\n",
    "    \n",
    "    #patient_id\n",
    "    info.append(patient_id)\n",
    "    \n",
    "    #image w,h,d\n",
    "    info.append(np.shape(patient_pixels)[2])\n",
    "    info.append(np.shape(patient_pixels)[1])\n",
    "    info.append(np.shape(patient_pixels)[0])\n",
    "    \n",
    "    #image volume mean\n",
    "    t1 = Timer('flatten pixels')\n",
    "    data = list(ndarray.flatten(patient_pixels))\n",
    "    t1.stop()\n",
    "    t1 = Timer('calc mean')\n",
    "    info.append(statistics.mean(data))\n",
    "    t1.stop()\n",
    "    \n",
    "    #slice original scan qtty,thickness\n",
    "    info.append(len(patient_scan))\n",
    "    info.append(patient_scan[0].slice_thickness)\n",
    "    \n",
    "    #mask cx,cy,cz,w,h,d\n",
    "    box = bounding_box(patient_lung_mask)\n",
    "    box_center = bounding_box_center(box)\n",
    "    info.append(box_center[0])\n",
    "    info.append(box_center[1])\n",
    "    info.append(box_center[2])\n",
    "    info.append(box[1][0]-box[0][0])\n",
    "    info.append(box[1][1]-box[0][1])\n",
    "    info.append(box[1][2]-box[0][2])\n",
    "    \n",
    "    #append data to csv file\n",
    "    with open(append_to_csv_file, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='\\'', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(info)\n",
    "        \n",
    "    t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_patient(input_dir, patient_id, output_shots_dir, output_csv_file):\n",
    "    patient_dir = input_dir + patient_id\n",
    "    patient_scan = load_scan(patient_dir)\n",
    "    patient_pixels = get_pixels_hu(patient_scan)\n",
    "    patient_pixels_resampled, spacing = resample(patient_pixels, patient_scan, [1,1,1])\n",
    "    patient_lung_mask = segment_lung_mask(patient_pixels_resampled, True)\n",
    "    \n",
    "    generate_patient_info(patient_pixels_resampled, patient_lung_mask, patient_scan, patient_id, output_csv_file)\n",
    "    \n",
    "    ln = np.shape(patient_pixels_resampled)[0]\n",
    "    generate_slice_shot(patient_pixels_resampled, patient_lung_mask, patient_id, int(ln/4), output_shots_dir)\n",
    "    generate_slice_shot(patient_pixels_resampled, patient_lung_mask, patient_id, int(ln/4*2), output_shots_dir)\n",
    "    generate_slice_shot(patient_pixels_resampled, patient_lung_mask, patient_id, int(ln/4*3), output_shots_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_processing(input_dir, shard_id, max_patients, output_dir):\n",
    "    log('Processing patients. shard_id=' + str(shard_id) + ' max_patients='+ str(max_patients) + ' input_dir=' + input_dir + ' output_dir=' + output_dir)\n",
    "    patient_ids = get_patient_ids(shard_id, input_dir)\n",
    "    log('Number of patients: ' + str(len(patient_ids)))\n",
    "    patients_count = 0\n",
    "    shutil.rmtree(output_dir, True)\n",
    "    try:\n",
    "        os.makedirs(output_dir + 'shots')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for patient_id in patient_ids:\n",
    "        patients_count = patients_count + 1\n",
    "        if(patients_count>max_patients):\n",
    "            break\n",
    "        t = Timer('>>> PATIENT PROCESSING ' + patient_id + ' (count=' + str(patients_count) + '; output_dir=' + output_dir + ')')\n",
    "        process_patient(input_dir, patient_id, output_dir + 'shots/', output_dir + 'patients.csv')\n",
    "        t.stop()\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== PROCESSING SHARD 2====\n",
      "2017-02-11 21:57:18.847793 Processing patients. shard_id=2 max_patients=99999 input_dir=../../input/sample_images/ output_dir=../../output/2/\n",
      "2017-02-11 21:57:18.848175 Number of patients: 10\n",
      "2017-02-11 21:57:18.848410 > [started] >>> PATIENT PROCESSING 0a0c32c9e08cc2ea76a71649de56be6d (count=1; output_dir=../../output/2/)...\n",
      "2017-02-11 21:57:18.848450 > [started] load_scan ../../input/sample_images/0a0c32c9e08cc2ea76a71649de56be6d...\n",
      "2017-02-11 21:57:18.956993 > [done]    load_scan ../../input/sample_images/0a0c32c9e08cc2ea76a71649de56be6d (108.527 ms)\n",
      "2017-02-11 21:57:19.083224 > [started] resample...\n",
      "2017-02-11 21:57:37.191760 > [done]    resample (18108.511 ms)\n",
      "2017-02-11 21:57:37.192001 > [started] segment_lung_mask...\n",
      "2017-02-11 21:57:43.233893 > [done]    segment_lung_mask (6041.859 ms)\n",
      "2017-02-11 21:57:43.245248 > [started] generate_patient_info...\n",
      "2017-02-11 21:57:43.245314 > [started] flatten pixels...\n",
      "2017-02-11 21:57:44.855255 > [done]    flatten pixels (1609.901 ms)\n",
      "2017-02-11 21:57:44.855358 > [started] calc mean...\n",
      "2017-02-11 21:58:08.158476 > [done]    calc mean (23303.098 ms)\n",
      "2017-02-11 21:58:08.233924 > [done]    generate_patient_info (24988.664 ms)\n",
      "2017-02-11 21:58:08.574054 > [started] generate_slice_shot 83...\n",
      "2017-02-11 21:58:08.715976 > [done]    generate_slice_shot 83 (141.912 ms)\n",
      "2017-02-11 21:58:08.716050 > [started] generate_slice_shot 166...\n",
      "2017-02-11 21:58:08.845087 > [done]    generate_slice_shot 166 (129.018 ms)\n",
      "2017-02-11 21:58:08.845223 > [started] generate_slice_shot 249...\n",
      "2017-02-11 21:58:08.982350 > [done]    generate_slice_shot 249 (137.110 ms)\n",
      "2017-02-11 21:58:08.984967 > [done]    >>> PATIENT PROCESSING 0a0c32c9e08cc2ea76a71649de56be6d (count=1; output_dir=../../output/2/) (50136.547 ms)\n",
      "\n",
      "2017-02-11 21:58:08.985037 > [started] >>> PATIENT PROCESSING 0a38e7597ca26f9374f8ea2770ba870d (count=2; output_dir=../../output/2/)...\n",
      "2017-02-11 21:58:08.985070 > [started] load_scan ../../input/sample_images/0a38e7597ca26f9374f8ea2770ba870d...\n",
      "2017-02-11 21:58:09.453978 > [done]    load_scan ../../input/sample_images/0a38e7597ca26f9374f8ea2770ba870d (468.895 ms)\n",
      "2017-02-11 21:58:09.558168 > [started] resample...\n",
      "2017-02-11 21:58:23.246718 > [done]    resample (13688.525 ms)\n",
      "2017-02-11 21:58:23.246885 > [started] segment_lung_mask...\n",
      "2017-02-11 21:58:28.248253 > [done]    segment_lung_mask (5001.337 ms)\n",
      "2017-02-11 21:58:28.257241 > [started] generate_patient_info...\n",
      "2017-02-11 21:58:28.257308 > [started] flatten pixels...\n",
      "2017-02-11 21:58:29.376905 > [done]    flatten pixels (1119.546 ms)\n",
      "2017-02-11 21:58:29.377006 > [started] calc mean...\n"
     ]
    }
   ],
   "source": [
    "print('==== PROCESSING SHARD ' + str(SHARD_ID) + '====')\n",
    "start_processing(INPUT_FOLDER, SHARD_ID, 99999, OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-11 21:23:05.759082 test\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
