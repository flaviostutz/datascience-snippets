{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#depth, height, width, channels\n",
    "IMAGE_DIMS = (224, 152, 224, 1)\n",
    "\n",
    "NR_SHARDS = 2\n",
    "\n",
    "SAVE_IMAGES = True\n",
    "\n",
    "INPUT_FOLDER = '../../output/step3/'\n",
    "OUTPUT_FOLDER = '../../output/step4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import h5py\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import csv\n",
    "import dicom\n",
    "import math\n",
    "from time import time\n",
    "import os\n",
    "import shutil\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "from skimage import measure, morphology, transform\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name, debug=True):\n",
    "        self._name = name\n",
    "        self._debug = debug\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        self._start = time()\n",
    "        if(self._debug):\n",
    "            logger.info('> [started] ' + self._name + '...')\n",
    "\n",
    "    def stop(self):\n",
    "        self._lastElapsed = (time()-self._start)\n",
    "        if(self._debug):\n",
    "            logger.info('> [done]    {} ({:.3f} ms)'.format(self._name, self._lastElapsed*1000))\n",
    "            \n",
    "    def elapsed(self):\n",
    "        if(self._lastElapsed != None):\n",
    "            return (self._lastElapsed)\n",
    "        else:\n",
    "            return (time()-self._start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "def setup_file_logger(log_file):\n",
    "    hdlr = logging.FileHandler(log_file)\n",
    "    hdlr.setLevel(logging.DEBUG)\n",
    "    hdlr.setFormatter(formatter)\n",
    "    logger.addHandler(hdlr) \n",
    "    logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(pixels, slice_pos, patient_id):\n",
    "    fig1, ax1 = plt.subplots(1)\n",
    "    fig1.set_size_inches(4,4)\n",
    "    ax1.imshow(pixels[round(np.shape(pixels)[0]*(slice_pos-1))][:,:,0], cmap=plt.cm.gray)\n",
    "    \n",
    "    if(SAVE_IMAGES):\n",
    "        file = OUTPUT_FOLDER + 'images/' + patient_id + '-' + 'slice-' + str(slice_pos) + '.jpg'\n",
    "        plt.savefig(file)\n",
    "        plt.close(fig1)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_slices(pixels, patient_id, nr_slices=12, cols=4):\n",
    "    fig = plt.figure()\n",
    "    slice_depth = round(np.shape(pixels)[0]/nr_slices)\n",
    "    rows = round(nr_slices/cols)+1\n",
    "    fig.set_size_inches(cols*10, rows*10)\n",
    "    for i in range(nr_slices):\n",
    "        slice_pos = int(slice_depth*i)\n",
    "        y = fig.add_subplot(rows,cols,i+1)\n",
    "        y.imshow(pixels[slice_pos][:,:,0], cmap='gray')\n",
    "        \n",
    "    if(SAVE_IMAGES):\n",
    "        file = OUTPUT_FOLDER + 'images/' + patient_id + '-' + 'slices.jpg'\n",
    "        plt.savefig(file)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_dataset(dataset_file):\n",
    "    logger.info('VALIDATING OUTPUT DATASET ' + dataset_file)\n",
    "\n",
    "    with h5py.File(dataset_file, 'r') as h5f:\n",
    "        x_ds = h5f['X']\n",
    "        y_ds = h5f['Y']\n",
    "\n",
    "        if(len(x_ds) != len(y_ds)):\n",
    "            logger.warning('VALIDATION ERROR: x and y datasets with different lengths')\n",
    "\n",
    "        for px in range(len(x_ds)):\n",
    "            arr = np.array(x_ds[px])\n",
    "            if(not np.any(arr)):\n",
    "                logger.warn('VALIDATION ERROR: No image found index=' + str(px))\n",
    "\n",
    "        for py in range(len(y_ds)):\n",
    "            arr = np.array(y_ds[py])\n",
    "            if(not np.any(arr)):\n",
    "                logger.warn('VALIDATION ERROR: No label found index=' + str(py) + 'label=' + str(arr))\n",
    "\n",
    "        logger.info('X shape=' + str(x_ds.shape))\n",
    "        logger.info('Y shape=' + str(y_ds.shape))\n",
    "\n",
    "        size = len(x_ds)\n",
    "        qtty = min(10, size)\n",
    "        f = size/qtty\n",
    "        for i in range(qtty):\n",
    "            pi = round(i*f)\n",
    "            logger.info('patient_index' + str(pi))\n",
    "            logger.info('x=')\n",
    "            show_slices(x_ds[pi], 'validation-' + str(pi))\n",
    "            logger.info('y=' + str(y_ds[pi]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_processing(input_dir, nr_shards, image_dims, output_dir):\n",
    "    logger.info('Merging shard results. nr_shards=' + str(nr_shards) + ' input_dir='+ str(input_dir) + ' output_dir=' + output_dir)\n",
    "    \n",
    "    t = Timer('Preparing output dir')\n",
    "    shutil.rmtree(output_dir, True)\n",
    "    try:\n",
    "        os.makedirs(output_dir + 'images')\n",
    "    except:\n",
    "        logger.error('Ops! Couldnt create output dir')\n",
    "        pass\n",
    "    t.stop()\n",
    "\n",
    "    setup_file_logger(output_dir + 'out.log')\n",
    "    \n",
    "    t = Timer('Count total patients among shards')\n",
    "    total_patients = 0\n",
    "    for shard_id in range(1,nr_shards+1):\n",
    "        dataset_file = input_dir + '{}/data-centered-rotated-{}-{}-{}.h5'.format(shard_id, image_dims[0], image_dims[1], image_dims[2])\n",
    "        with h5py.File(dataset_file, 'r') as h5f:\n",
    "            logger.info('shard_id={} shape={}'.format(shard_id,h5f['X'].shape))\n",
    "            total_patients = total_patients + len(h5f['X'])\n",
    "    t.stop()\n",
    "            \n",
    "    logger.info('total_patients=' + str(total_patients))\n",
    "\n",
    "    t = Timer('Creating output merged dataset')\n",
    "    output_dataset_file = output_dir + 'data-centered-rotated-{}-{}-{}.h5'.format(image_dims[0], image_dims[1], image_dims[2])\n",
    "    with h5py.File(output_dataset_file, 'w') as h5f:\n",
    "        x_ds = h5f.create_dataset('X', (total_patients, image_dims[0], image_dims[1], image_dims[2], image_dims[3]), chunks=(1, image_dims[0], image_dims[1], image_dims[2], image_dims[3]), dtype='f')\n",
    "        y_ds = h5f.create_dataset('Y', (total_patients, 2), dtype='f')\n",
    "\n",
    "        logger.info('Merging shards')\n",
    "        pb = 0\n",
    "        for shard_id in range(1,nr_shards+1):\n",
    "            ts = Timer('Processing shard' + str(shard_id))\n",
    "            dataset_file = input_dir + '{}/data-centered-rotated-{}-{}-{}.h5'.format(shard_id, image_dims[0], image_dims[1], image_dims[2])\n",
    "            with h5py.File(dataset_file, 'r') as sh5f:\n",
    "                shard_x_ds = sh5f['X']\n",
    "                shard_y_ds = sh5f['Y']\n",
    "                le = len(shard_x_ds)\n",
    "                pe = pb + le\n",
    "                logger.debug('output' + str(pb) + ' ' + str(pe) + ' input ' + str(0) + str(le))\n",
    "                x_ds[pb:pe] = shard_x_ds[0:le]\n",
    "                y_ds[pb:pe] = shard_y_ds[0:le]\n",
    "                pb = pe\n",
    "            ts.stop()\n",
    "    t.stop()\n",
    "    \n",
    "    t = Timer('Output dataset validations')\n",
    "    validate_dataset(output_dataset_file)\n",
    "    t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-19 19:55:23,915 INFO > [started] Count total patients among shards...\n",
      "2017-02-19 19:55:23,917 INFO shard_id=1 shape=(19, 224, 152, 224, 1)\n",
      "2017-02-19 19:55:23,919 INFO shard_id=2 shape=(19, 224, 152, 224, 1)\n",
      "2017-02-19 19:55:23,920 INFO > [done]    Count total patients among shards (4.851 ms)\n",
      "2017-02-19 19:55:23,921 INFO total_patients=38\n",
      "2017-02-19 19:55:23,922 INFO > [started] Creating output merged dataset...\n",
      "2017-02-19 19:55:23,924 INFO Merging shards\n",
      "2017-02-19 19:55:23,925 INFO > [started] Processing shard1...\n",
      "2017-02-19 19:55:24,749 INFO > [done]    Processing shard1 (824.677 ms)\n",
      "2017-02-19 19:55:24,750 INFO > [started] Processing shard2...\n",
      "2017-02-19 19:55:25,602 INFO > [done]    Processing shard2 (851.977 ms)\n",
      "2017-02-19 19:55:25,611 INFO > [done]    Creating output merged dataset (1688.656 ms)\n",
      "2017-02-19 19:55:25,611 INFO > [started] Output dataset validations...\n",
      "2017-02-19 19:55:25,612 INFO VALIDATING OUTPUT DATASET ../../output/step4/data-centered-rotated-224-152-224.h5\n",
      "2017-02-19 19:55:26,295 INFO X shape=(38, 224, 152, 224, 1)\n",
      "2017-02-19 19:55:26,296 INFO Y shape=(38, 2)\n",
      "2017-02-19 19:55:26,297 INFO patient_index0\n",
      "2017-02-19 19:55:26,299 INFO x=\n",
      "2017-02-19 19:55:28,224 INFO y=[ 1.  0.]\n",
      "2017-02-19 19:55:28,225 INFO patient_index4\n",
      "2017-02-19 19:55:28,226 INFO x=\n",
      "2017-02-19 19:55:30,189 INFO y=[ 0.  1.]\n",
      "2017-02-19 19:55:30,190 INFO patient_index8\n",
      "2017-02-19 19:55:30,190 INFO x=\n",
      "2017-02-19 19:55:32,557 INFO y=[ 1.  0.]\n",
      "2017-02-19 19:55:32,558 INFO patient_index11\n",
      "2017-02-19 19:55:32,559 INFO x=\n",
      "2017-02-19 19:55:34,593 INFO y=[ 0.  1.]\n",
      "2017-02-19 19:55:34,599 INFO patient_index15\n",
      "2017-02-19 19:55:34,600 INFO x=\n",
      "2017-02-19 19:55:36,531 INFO y=[ 0.  1.]\n",
      "2017-02-19 19:55:36,532 INFO patient_index19\n",
      "2017-02-19 19:55:36,533 INFO x=\n",
      "2017-02-19 19:55:38,509 INFO y=[ 1.  0.]\n",
      "2017-02-19 19:55:38,510 INFO patient_index23\n",
      "2017-02-19 19:55:38,511 INFO x=\n",
      "2017-02-19 19:55:40,521 INFO y=[ 0.  1.]\n",
      "2017-02-19 19:55:40,522 INFO patient_index27\n",
      "2017-02-19 19:55:40,522 INFO x=\n",
      "2017-02-19 19:55:42,333 INFO y=[ 1.  0.]\n",
      "2017-02-19 19:55:42,335 INFO patient_index30\n",
      "2017-02-19 19:55:42,335 INFO x=\n",
      "2017-02-19 19:55:44,388 INFO y=[ 0.  1.]\n",
      "2017-02-19 19:55:44,389 INFO patient_index34\n",
      "2017-02-19 19:55:44,390 INFO x=\n",
      "2017-02-19 19:55:46,249 INFO y=[ 0.  1.]\n",
      "2017-02-19 19:55:46,250 INFO > [done]    Output dataset validations (20638.753 ms)\n",
      "2017-02-19 19:55:46,251 INFO ==== ALL DONE ====\n"
     ]
    }
   ],
   "source": [
    "logger.info('==== PROCESSING SHARDS MERGE ====')\n",
    "start_processing(INPUT_FOLDER, NR_SHARDS, IMAGE_DIMS, OUTPUT_FOLDER)\n",
    "logger.info('==== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
