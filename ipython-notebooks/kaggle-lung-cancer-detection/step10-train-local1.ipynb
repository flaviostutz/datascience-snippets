{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (50,34,50,1)\n",
    "# IMAGE_DIMS = (112,76,112,1)\n",
    "OUTPUT_DIR = '../../../output/kaggle-bowl/step10/'\n",
    "INPUT_DIR = '../../../input/step5-50/'\n",
    "# INPUT_DIR = '../../../input/step5-112/'\n",
    "DATASET_NAME_SUFFIX = '-centered-rotated'\n",
    "LOAD_MODEL_FILE = None\n",
    "#LOAD_MODEL_FILE = OUTPUT_DIR + 'tf-checkpoint-best5556'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import logging\n",
    "import tflearn\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.logging\n",
    "import modules.lungprepare as lungprepare\n",
    "import modules.utils as utils\n",
    "import modules.cnn as cnn\n",
    "from modules.utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def start_training(model, input_dir, dataset_name_suffix, image_dims, output_dir):\n",
    "\n",
    "    utils.mkdirs(output_dir, recreate=False)\n",
    "\n",
    "    modules.logging.setup_file_logger(output_dir + 'out.log')\n",
    "    \n",
    "    dataset_path = utils.dataset_path(input_dir, 'train' + dataset_name_suffix, IMAGE_DIMS)\n",
    "    with h5py.File(dataset_path, 'r') as train_hdf5:\n",
    "        X = train_hdf5['X']\n",
    "        Y = train_hdf5['Y']\n",
    "        logger.info('X shape ' + str(X.shape))\n",
    "        logger.info('Y shape ' + str(Y.shape))\n",
    "\n",
    "        dataset_path = utils.dataset_path(input_dir, 'validate' + dataset_name_suffix, image_dims)\n",
    "        with h5py.File(dataset_path, 'r') as validate_hdf5:\n",
    "            X_validate = validate_hdf5['X']\n",
    "            Y_validate = validate_hdf5['Y']\n",
    "            logger.info('X_validate shape ' + str(X_validate.shape))\n",
    "            logger.info('Y_validate shape ' + str(Y_validate.shape))\n",
    "\n",
    "            logger.info('Starting CNN training...')\n",
    "            model.fit(X, Y, validation_set=(X_validate, Y_validate), \n",
    "                      shuffle=True, batch_size=50, n_epoch=40,\n",
    "                      show_metric=True, \n",
    "                      run_id='simplest1-'+str(image_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-08 12:03:28,962 INFO Prepare CNN for training\n",
      "2017-03-08 12:03:29,040 INFO Prepare CNN\n",
      "2017-03-08 12:03:29,041 INFO Preparing output dir\n",
      "2017-03-08 12:03:29,042 INFO Initializing network...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Prepare CNN for training')\n",
    "#network = cnn.net_simplest1(IMAGE_DIMS)\n",
    "#network = cnn.net_deepmedic_simple(IMAGE_DIMS)\n",
    "network = cnn.net_alzheimer_cnn(IMAGE_DIMS)\n",
    "model = cnn.prepare_cnn_model(network, OUTPUT_DIR, model_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.22516\u001b[0m\u001b[0m | time: 10.819s\n",
      "| Adam | epoch: 040 | loss: 0.22516 - acc: 0.9300 -- iter: 500/538\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.22198\u001b[0m\u001b[0m | time: 12.903s\n",
      "| Adam | epoch: 040 | loss: 0.22198 - acc: 0.9270 | val_loss: 1.43148 - val_acc: 0.4000 -- iter: 538/538\n",
      "--\n",
      "INFO:tensorflow:/notebooks/output/kaggle-bowl/step10/tf-checkpoint-440 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-08 12:12:16,460 INFO /notebooks/output/kaggle-bowl/step10/tf-checkpoint-440 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/notebooks/output/kaggle-bowl/step10/final is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-08 12:12:16,912 INFO /notebooks/output/kaggle-bowl/step10/final is not in all_model_checkpoint_paths. Manually adding it.\n",
      "2017-03-08 12:12:16,992 INFO ==== ALL DONE ====\n"
     ]
    }
   ],
   "source": [
    "logger.info('Train CNN')\n",
    "start_training(model, INPUT_DIR, DATASET_NAME_SUFFIX, IMAGE_DIMS, OUTPUT_DIR)\n",
    "model.save(OUTPUT_DIR + 'final')\n",
    "logger.info('==== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-08 12:12:16,998 INFO Evaluate model from dataset\n",
      "2017-03-08 12:12:16,999 DEBUG X_test shape (90, 50, 34, 50, 1)\n",
      "2017-03-08 12:12:17,001 DEBUG Y_test shape (90, 2)\n",
      "2017-03-08 12:12:17,001 INFO Evaluate performance on dataset ../../../input/step5-50/validate-centered-rotated-50-34-50.h5...\n",
      "2017-03-08 12:12:18,004 INFO Accuracy: [0.40000001192092893]\n"
     ]
    }
   ],
   "source": [
    "logger.info('Evaluate model from dataset')\n",
    "dataset_path = utils.dataset_path(INPUT_DIR, 'validate' + DATASET_NAME_SUFFIX, IMAGE_DIMS)\n",
    "cnn.evaluate_dataset(dataset_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
