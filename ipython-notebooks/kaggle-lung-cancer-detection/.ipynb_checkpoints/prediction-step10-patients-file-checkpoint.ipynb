{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (224, 152, 224, 1)\n",
    "\n",
    "SAVE_IMAGES = True\n",
    "\n",
    "INPUT_FOLDER = '../../input/sample_images/'\n",
    "OUTPUT_FOLDER = '../../output/step10/'\n",
    "\n",
    "PATIENTS_FILE = '../../input/sample_dummy_submission.csv'\n",
    "CNN_MODEL_FILE = OUTPUT_FOLDER + 'train-local/tf-checkpoint-best7826'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import h5py\n",
    "from random import shuffle\n",
    "import numpy as np # linear algebra\n",
    "from numpy import ndarray\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import statistics\n",
    "import csv\n",
    "import dicom\n",
    "import math\n",
    "from time import time\n",
    "import os\n",
    "import shutil\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "from skimage import measure, morphology, transform\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import logging\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import *\n",
    "from tflearn.layers.conv import *\n",
    "from tflearn.data_utils import *\n",
    "from tflearn.layers.normalization import *\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name, debug=True):\n",
    "        self._name = name\n",
    "        self._debug = debug\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        self._start = time()\n",
    "        if(self._debug):\n",
    "            logger.info('> [started] ' + self._name + '...')\n",
    "\n",
    "    def stop(self):\n",
    "        self._lastElapsed = (time()-self._start)\n",
    "        if(self._debug):\n",
    "            logger.info('> [done]    {} ({:.3f} ms)'.format(self._name, self._lastElapsed*1000))\n",
    "            \n",
    "    def elapsed(self):\n",
    "        if(self._lastElapsed != None):\n",
    "            return (self._lastElapsed)\n",
    "        else:\n",
    "            return (time()-self._start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "def setup_file_logger(log_file):\n",
    "    hdlr = logging.FileHandler(log_file)\n",
    "    hdlr.setLevel(logging.DEBUG)\n",
    "    hdlr.setFormatter(formatter)\n",
    "    logger.addHandler(hdlr) \n",
    "    logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_slices(pixels, patient_id, nr_slices=12, cols=4):\n",
    "    fig = plt.figure()\n",
    "    slice_depth = round(np.shape(pixels)[0]/nr_slices)\n",
    "    rows = round(nr_slices/cols)+1\n",
    "    fig.set_size_inches(cols*10, rows*10)\n",
    "    for i in range(nr_slices):\n",
    "        slice_pos = int(slice_depth*i)\n",
    "        y = fig.add_subplot(rows,cols,i+1)\n",
    "        im = pixels[slice_pos]\n",
    "        if(len(np.shape(im))>2):\n",
    "            im = im[:,:,0]\n",
    "        y.imshow(im, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_next_valid(line, bgs=[]):\n",
    "    for e in line:\n",
    "        if(e not in bgs):\n",
    "            return e\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the scans in given folder path\n",
    "#image pixels dimensions: z, y, x\n",
    "def load_scan(path):\n",
    "    t = Timer('load_scan ' + path)\n",
    "    \n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.slice_thickness = slice_thickness\n",
    "\n",
    "    t.stop()\n",
    "    return slices\n",
    "\n",
    "#image pixels dimensions: z, y, x\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "#image pixels dimensions: z, y, x\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    t = Timer('resample')\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].slice_thickness] + scan[0].PixelSpacing, dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    t.stop()\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "def largest_label_volume(im, bgs=[]):\n",
    "    vals, counts = np.unique(im, return_counts=True)\n",
    "    for bg in bgs:\n",
    "        counts = counts[vals != bg]\n",
    "        vals = vals[vals != bg]\n",
    "    if len(counts) > 0:\n",
    "        return vals[np.argmax(counts)]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def segment_lung_mask(image, fill_lung_structures=True):\n",
    "    t = Timer('segment_lung_mask')\n",
    "    \n",
    "    # 0 is treated as background, which we do not want\n",
    "    binary_image = np.array(image > -320, dtype=np.int8)+1\n",
    "    \n",
    "    #cleanup some small bubbles inside body before labelling\n",
    "    binary_image = scipy.ndimage.morphology.grey_closing(binary_image, 3)\n",
    "\n",
    "    labels = measure.label(binary_image)\n",
    "    \n",
    "    #Determine which label clusters refers to the air/space around the person body and turn it into the same cluster\n",
    "    #The various corners are measured in case of volume being broken when the body is not fitted inside scan\n",
    "    bgs = [0]\n",
    "    si = np.shape(binary_image)\n",
    "    si0 = si[0]-3\n",
    "    si1 = si[1]-3\n",
    "    si2 = si[2]-3\n",
    "    for i in (2, si0):\n",
    "        for j in (2, si1):\n",
    "            for k in (2, si2):\n",
    "                bgs.append(labels[i,j,k])\n",
    "\n",
    "    #identify the body label\n",
    "    s = np.array(np.shape(labels))\n",
    "    body = find_next_valid(labels[round(s[0]*0.6), round(s[1]*0.5)], bgs=bgs)\n",
    "    bgs.append(body)\n",
    "    logger.debug('bgs' + str(bgs))\n",
    "\n",
    "    #look inside the volume where lung structures is meant to be\n",
    "    lung_label = largest_label_volume(labels[s[0]*0.2:s[0]*0.8, s[1]*0.25:s[1]*0.75, s[2]*0.25:s[2]*0.75], bgs=bgs)\n",
    "    logger.debug('lung_label' + str(lung_label))\n",
    "\n",
    "    #remove everything that is not part of the lung\n",
    "    logger.debug('remove non lung structures')\n",
    "    binary_image[labels != lung_label] = 2\n",
    "    \n",
    "    # Method of filling the lung structures (that is superior to something like \n",
    "    # morphological closing)\n",
    "    if fill_lung_structures:\n",
    "        # For every slice we determine the largest solid structure\n",
    "        for i, axial_slice in enumerate(binary_image):\n",
    "            axial_slice = axial_slice - 1\n",
    "            labeling = measure.label(axial_slice)\n",
    "            l_max = largest_label_volume(labeling, bgs=[0])\n",
    "            if l_max is not None: #This slice contains some lung\n",
    "                binary_image[i][labeling != l_max] = 1\n",
    "    logger.debug('fill_lung_structures')\n",
    "    \n",
    "    binary_image -= 1 #Make the image actual binary\n",
    "    binary_image = 1-binary_image # Invert it, lungs are now 1\n",
    "    \n",
    "    #dilate mask\n",
    "    binary_image = scipy.ndimage.morphology.grey_dilation(binary_image, size=(10,10,10))\n",
    "    t.stop()\n",
    "    \n",
    "    return binary_image\n",
    "\n",
    "#returns ((x1, y1, z1), (x2, y2, z2))\n",
    "def bounding_box(img):\n",
    "    N = img.ndim\n",
    "    out = []\n",
    "    for ax in itertools.combinations(range(N), N - 1):\n",
    "        nonzero = np.any(img, axis=ax)\n",
    "        out.extend(np.where(nonzero)[0][[0, -1]])\n",
    "    r = np.reshape(np.asarray(tuple(out)), (-1, 2)).T\n",
    "    return [tuple(r[0]), tuple(r[1])]\n",
    "\n",
    "#return bounding box center in (x,y,z)\n",
    "def bounding_box_center(bounds):\n",
    "    return (int(round((bounds[0][0] + (bounds[1][0]-bounds[0][0])/2))), int(round((bounds[0][1] + (bounds[1][1]-bounds[0][1])/2))), int(round((bounds[0][2] + (bounds[1][2]-bounds[0][2])/2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find lungs rotation by finding minimum and maximum extremities from lung halves\n",
    "def find_minmax_halfx(lung_mask, xhalf, bottom2up=True, left2right=True, slicen=220):\n",
    "    xsize = np.shape(lung_mask)[2]-1\n",
    "    ysize = np.shape(lung_mask)[1]-1\n",
    "    im = np.swapaxes(lung_mask[slicen], 0, 1)\n",
    "\n",
    "    if(bottom2up): mvalue = (-1,0)\n",
    "    else: mvalue = (-1, ysize)\n",
    "        \n",
    "    if(left2right): \n",
    "        xstart = 0\n",
    "        xend = xhalf\n",
    "        xdir = 1\n",
    "    else:\n",
    "        xstart = xsize\n",
    "        xend = xhalf\n",
    "        xdir = -1\n",
    "        \n",
    "    for x in range(xstart, xend, xdir):\n",
    "        for y in range(ysize):\n",
    "            if(not bottom2up): yi = ysize - y\n",
    "            else: yi = y\n",
    "\n",
    "            if(im[x][yi]>0.5):\n",
    "                if(bottom2up and yi>mvalue[1]):\n",
    "                    mvalue = (x, yi)\n",
    "                elif(not bottom2up and yi<mvalue[1]):\n",
    "                    mvalue = (x, yi)\n",
    "    return mvalue\n",
    "    \n",
    "def calculate_angle(p1, p2):\n",
    "    return math.degrees(math.atan2(p2[1]-p1[1],p2[0]-p1[0]))\n",
    "\n",
    "def value_between(value, min_value, max_value):\n",
    "    if(value<min_value): return False\n",
    "    if(value>max_value): return False\n",
    "    return True\n",
    "\n",
    "def discover_lung_rotation(lung_mask):\n",
    "    bbox = bounding_box(lung_mask)\n",
    "    if(bbox == None): return 0\n",
    "    slicen = int((bbox[1][2]-bbox[0][2])/2)\n",
    "    half = int(bbox[0][0]+(bbox[1][0]-bbox[0][0])/2)\n",
    "\n",
    "    l1 = find_minmax_halfx(lung_mask, half, bottom2up=True, left2right=True, slicen=slicen)\n",
    "    r1 = find_minmax_halfx(lung_mask, half, bottom2up=True, left2right=False, slicen=slicen)\n",
    "    l2 = find_minmax_halfx(lung_mask, half, bottom2up=False, left2right=True, slicen=slicen)\n",
    "    r2 = find_minmax_halfx(lung_mask, half, bottom2up=False, left2right=False, slicen=slicen)\n",
    "\n",
    "    r = (l1, r1, l2, r2)\n",
    "    xs, ys = zip(*r)\n",
    "    \n",
    "    #verify points sanity\n",
    "    if(not value_between(xs[1]-xs[0], 50, 200) or\n",
    "       not value_between(xs[3]-xs[2], 50, 200) or\n",
    "       not value_between(ys[0]-ys[2], 100, 250) or\n",
    "       not value_between(ys[1]-ys[3], 100, 250)):\n",
    "        logger.warning('Strange rotation detected. returning 0 degrees')\n",
    "        return 0\n",
    "    \n",
    "    angle1 = calculate_angle(l1, r1)\n",
    "    angle2 = calculate_angle(l2, r2)\n",
    "    \n",
    "    a = ((angle1 + angle2)/2)\n",
    "    return min(max(a, -10), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def diff_for_shiffiting(point1, point2):\n",
    "    t = np.subtract(point1, point2)\n",
    "    return (t[2], t[1], t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bbox_dim(bbox):\n",
    "    bw = bbox[1][0]-bbox[0][0]\n",
    "    bh = bbox[1][1]-bbox[0][1]\n",
    "    bd = bbox[1][2]-bbox[0][2]\n",
    "    return bw,bh,bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_patient_images(patient_dir, image_dims):\n",
    "    patient_scan = load_scan(patient_dir)\n",
    "    patient_pixels = get_pixels_hu(patient_scan)\n",
    "    patient_pixels, spacing = resample(patient_pixels, patient_scan, [1,1,1])\n",
    "    patient_lung_mask = segment_lung_mask(patient_pixels, True)\n",
    "    \n",
    "    t = Timer('apply lung mask to image volume')\n",
    "    patient_pixels = np.ma.masked_where(patient_lung_mask==0, patient_pixels).filled(fill_value=0)\n",
    "    t.stop()\n",
    "\n",
    "    t = Timer('rotate image for optimal pose')\n",
    "    rotation_angle = discover_lung_rotation(patient_lung_mask)\n",
    "    patient_pixels = rotate(patient_pixels,rotation_angle,(1,2), reshape=False)\n",
    "    t.stop()\n",
    "    \n",
    "    t = Timer('resize image volume to {}x{}x{}'.format(image_dims[0], image_dims[1], image_dims[2]))\n",
    "    bbox = bounding_box(patient_pixels)\n",
    "    if(bbox == None):\n",
    "        return None\n",
    "    bw,bh,bd = bbox_dim(bbox)\n",
    "    fit_volume = (image_dims[2], image_dims[1], image_dims[0])\n",
    "    ratio = min(tuple(np.divide(fit_volume,np.subtract(bbox[1],bbox[0]))))\n",
    "    logger.debug('ratio=' + str(ratio))\n",
    "   \n",
    "    patient_pixels = scipy.ndimage.interpolation.zoom(patient_pixels[bbox[0][2]:bbox[1][2],bbox[0][1]:bbox[1][1],bbox[0][0]:bbox[1][0]], ratio)\n",
    "    t.stop()\n",
    "\n",
    "    t = Timer('translate to center')\n",
    "    fit_volume_center = tuple(np.divide(fit_volume, 2))\n",
    "    bbox = bounding_box(patient_pixels)\n",
    "    bbox_center = bounding_box_center(bbox)\n",
    "\n",
    "    patient_pixels2 = np.full((image_dims[0], image_dims[1], image_dims[2]),0)\n",
    "    ps = np.shape(patient_pixels)\n",
    "    patient_pixels2[:ps[0],:ps[1],:ps[2]] = patient_pixels[:ps[0],:ps[1],:ps[2]]\n",
    "    patient_pixels = patient_pixels2\n",
    "    \n",
    "    diff = (np.subtract(fit_volume_center,bbox_center))\n",
    "    patient_pixels = shift(patient_pixels, (diff[2],diff[1],diff[0]))\n",
    "    t.stop()\n",
    "\n",
    "    #normalization for better training on neural networks\n",
    "    t = Timer('pixel normalization')\n",
    "    MIN_BOUND = -1000.0\n",
    "    MAX_BOUND = 400.0\n",
    "    \n",
    "    patient_pixels = (patient_pixels - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    patient_pixels[patient_pixels>1] = 1.\n",
    "    patient_pixels[patient_pixels<0] = 0.\n",
    "\n",
    "    #0-center pixels\n",
    "    logger.debug('mean pixels=' + str(np.mean(patient_pixels)))\n",
    "    PIXEL_MEAN = 0.6 #calculated before\n",
    "    patient_pixels = patient_pixels - PIXEL_MEAN\n",
    "    t.stop()\n",
    "    \n",
    "    #add color channel dimension\n",
    "    patient_pixels = np.expand_dims(patient_pixels, axis=3)\n",
    "    \n",
    "    return patient_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_patient_ids(patients_file):\n",
    "    patients = []\n",
    "    \n",
    "    file = csv.DictReader(open(patients_file))\n",
    "    for row in file:\n",
    "        p = row['id']\n",
    "        patients.append(p)\n",
    "    logger.info('found {} patients for prediction'.format(len(patients)))\n",
    "    \n",
    "    return patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(image_dims):\n",
    "    net = input_data(shape=[None, image_dims[0], image_dims[1], image_dims[2], image_dims[3]], dtype=tf.float32)\n",
    "    \n",
    "    net = conv_3d(net, 32, 3, strides=1, activation='relu')\n",
    "    net = max_pool_3d(net, [1,2,2,2,1], strides=[1,2,2,2,1])\n",
    "\n",
    "    net = conv_3d(net, 64, 3, strides=1, activation='relu')\n",
    "    net = max_pool_3d(net, [1,2,2,2,1], strides=[1,2,2,2,1])\n",
    "    \n",
    "    net = fully_connected(net, 64, activation='relu')\n",
    "    net = dropout(net, 0.8)\n",
    "    \n",
    "    net = fully_connected(net, 2, activation='softmax')\n",
    "    \n",
    "    net = regression(net, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def prepare_cnn(cnn_model_file, image_dims):\n",
    "#     logger.info('Loading CNN network...')\n",
    "#     net = network(image_dims)\n",
    "\n",
    "#     logger.info('Preparing DNN engine...')\n",
    "#     model = tflearn.DNN(net)\n",
    "# #     model = tflearn.DNN(net, tensorboard_verbose=3, \n",
    "# #                              tensorboard_dir='/tmp/tflearn_logs',\n",
    "# #                              checkpoint_path='/tmp/tflearn_ckpt',\n",
    "# #                              best_checkpoint_path='/tmp/tflearn_ckpt_best')\n",
    "\n",
    "#     logger.info('Loading CNN model...')\n",
    "#     model.load(cnn_model_file)\n",
    "        \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_patient(model, input_dir, patient_id, image_dims):\n",
    "    logger.info('>>> Predict patient_id ' + patient_id)\n",
    "    logger.info('Loading pre-processed images for patient')\n",
    "\n",
    "    dataset_file = output_dir + 'predict-centered-rotated-{}-{}-{}.h5'.format(image_dims[0], image_dims[1], image_dims[2])\n",
    "    \n",
    "    #patient pre-processed image cache\n",
    "    patient_pixels = None\n",
    "    with h5py.File(dataset_file, 'a') as h5f:\n",
    "        patient_pixels = h5f[patient_id]\n",
    "        if(patient_pixels is None):\n",
    "            t = Timer('Patient image cache not found. Preparing it. patient_id=' + patient_id)\n",
    "            patient_pixels = process_patient_images(input_dir + patient_id, image_dims)\n",
    "            if(patient_pixels is None):\n",
    "                logger.warning('Patient lung not found. Skipping.')\n",
    "            logger.debug('Storing patient image on cache')\n",
    "            h5py[patient_id] = patient_pixels\n",
    "            t.stop()\n",
    "        else:\n",
    "            logger.debug('Patient image found on cache. Using it.')\n",
    "            #disconnect from HDF5\n",
    "            patient_pixels = np.array(patient_pixels)\n",
    "    \n",
    "    t = Timer('Predicting result on CNN (forward)')\n",
    "    y = model.predict(patient_pixels)\n",
    "    logger.info('PATIENT '+ patient_id +' PREDICT=' + str(y))\n",
    "    show_slices(patient_pixels, patient_id)\n",
    "    t.stop()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_processing(input_dir, patients_file, cnn_model_file, max_patients, image_dims, output_dir):\n",
    "    logger.info('Predicting patients. ' + ' max_patients='+ str(max_patients) + ' input_dir=' + input_dir + ' output_dir=' + output_dir)\n",
    "    \n",
    "    logger.info('Preparing output dir')\n",
    "#     shutil.rmtree(output_dir, True)\n",
    "    try:\n",
    "        os.makedirs(output_dir + 'images/')\n",
    "    except:\n",
    "        logger.warning('Ops! Couldnt create output dir')\n",
    "        pass\n",
    "\n",
    "    setup_file_logger(output_dir + 'out.log')\n",
    "\n",
    "    model = tflearn.DNN(network(image_dims))\n",
    "#     model = prepare_cnn(cnn_model_file, image_dims)\n",
    "    \n",
    "    logger.info('Collect patient ids for analysis')\n",
    "    patient_ids = get_patient_ids(patients_file)\n",
    "    total_patients = len(patient_ids)\n",
    "    logger.debug('Found ' + str(total_patients) + ' patients')\n",
    "\n",
    "    for patient_id in patient_ids:\n",
    "        if(count>(max_patients-1)):\n",
    "            break\n",
    "            \n",
    "        y = predict_patient(model, input_dir, patient_id, image_dims)\n",
    "        logger.info(\"Prediction for patient \" + patient_id + ' is ' + str(y))\n",
    "\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-20 04:12:36,345 WARNING Ops! Couldnt create output dir\n",
      "2017-02-20 04:12:36,346 INFO Loading CNN network...\n",
      "2017-02-20 04:12:36,546 INFO Preparing DNN engine...\n",
      "2017-02-20 04:13:04,769 INFO Loading CNN model...\n"
     ]
    }
   ],
   "source": [
    "logger.info('==== PROCESSING PREDICTION ====')\n",
    "start_processing(INPUT_FOLDER, PATIENTS_FILE, CNN_MODEL_FILE, 1, IMAGE_DIMS, OUTPUT_FOLDER)\n",
    "logger.info('==== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
