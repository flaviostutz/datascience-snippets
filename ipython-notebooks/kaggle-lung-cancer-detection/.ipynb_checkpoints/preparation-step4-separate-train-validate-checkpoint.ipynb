{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only (patient_id%NR_SHARDS) == SHARD_ID will be processed here\n",
    "#choose a value between 1-NR_SHARDS\n",
    "SHARD_ID = 1\n",
    "IMAGE_W = 256\n",
    "IMAGE_H = 256\n",
    "IMAGE_D = 256\n",
    "PERC_TRAIN = 0.8\n",
    "PERC_VALIDATE = 0.1\n",
    "PERC_TEST = 0.1\n",
    "\n",
    "NR_SHARDS = 4\n",
    "\n",
    "#Patient DICOM images folder\n",
    "INPUT_FOLDER = '../../input/sample_images/'\n",
    "OUTPUT_FOLDER = '../../output/step3/' + str(SHARD_ID) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import panda as pd\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_patient_ids(shard_id, input_dir):\n",
    "    shard_patients = []\n",
    "    \n",
    "    file = csv.DictReader(open(input_dir + 'stage1_labels.csv'))    \n",
    "    for row in file:\n",
    "        p = row['id']\n",
    "        if(int(p,16)%NR_SHARDS == (shard_id-1)):\n",
    "            shard_patients.append(p)\n",
    "            \n",
    "    return shuffle(shard_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_patient_label(input_dir, patient_id, output_dataset, dataset_row):\n",
    "    labels = pd.read_csv(input_dir + 'stage1_labels.csv', index_col=0)\n",
    "    value = labels.get_value(patient, 'cancer')\n",
    "    #one-hot encoding\n",
    "    label = np.array([0,1])\n",
    "    if(value == 0): label = np.array([1,0])\n",
    "    output_dataset[dataset_row] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_patient_images(shard_id, input_dir, output_dir, image_w, image_h, image_d, output_dataset):\n",
    "    data_images = []\n",
    "    patients = get_shard_patient_ids(shard_id, input_dir)\n",
    "    for patient in patients:\n",
    "        data_images.append([img_data,label])\n",
    "\n",
    "    np.save('muchdata-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), much_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-9-4723151b6e0e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-4723151b6e0e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def process_labels_data():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_processing(input_dir, shard_id, max_patients, perc_train, perc_validate, perc_test, image_w, image_h, image_d, output_dir):\n",
    "    log('Processing patients. shard_id=' + str(shard_id) + ' max_patients='+ str(max_patients) + ' input_dir=' + input_dir + ' output_dir=' + output_dir)\n",
    "    \n",
    "    log('Gathering patient ids for this shard')\n",
    "    patient_ids = get_patient_ids(shard_id, input_dir)\n",
    "    nr_patients_train = round(len(patient_ids)*perc_train)\n",
    "    nr_patients_validate = round(len(patient_ids)*perc_validate)\n",
    "    \n",
    "    log('Preparing output dir')\n",
    "    shutil.rmtree(output_dir, True)\n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    log('Creating datasets')\n",
    "    h5f = h5py.File(output_dir + 'data-{}-{}-{}.h5'.format(image_w, image_h, image_d), 'w')\n",
    "    train_x_ds = h5f.create_dataset('train_X', (, image_d, image_h, image_w), chunks=(5, image_d, image_h, image_w), dtype='f')\n",
    "    train_y_ds = h5f.create_dataset('train_Y', ())\n",
    "    validate_x_ds = h5f.create_dataset('validate_X', ())\n",
    "    validate_y_ds = h5f.create_dataset('validate_Y', ())\n",
    "    test_x_ds = h5f.create_dataset('test_X', ())\n",
    "    test_y_ds = h5f.create_dataset('test_Y', ())\n",
    "\n",
    "    log('Starting to process each patient (count={})'.format(len(patient_ids)))\n",
    "    count = 0\n",
    "    current_ds_row = 0\n",
    "    current_x_ds = train_x_ds\n",
    "    current_y_ds = train_y_ds\n",
    "\n",
    "    for patient_id in patient_ids:\n",
    "\n",
    "        if(count>max_patients):\n",
    "            break\n",
    "\n",
    "        if(count == nr_patients_train):\n",
    "            current_x_ds = validate_x_ds\n",
    "            current_y_ds = validate_y_ds\n",
    "            current_ds_row = 0\n",
    "            \n",
    "        elif(count == (nr_patients_train + nr_patients_validate)):\n",
    "            current_x_ds = test_x_ds\n",
    "            current_y_ds = test_y_ds\n",
    "            current_ds_row = 0\n",
    "            \n",
    "        t = Timer('>>> PATIENT PROCESSING ' + patient_id + ' (count=' + str(patients_count) + '; output_dir=' + output_dir + ')')\n",
    "        process_patient_images(input_dir, patient_id, image_w, image_h, image_d, current_x_ds, current_ds_row)\n",
    "        process_patient_label(input_dir, patient_id, current_y_ds, dataset_row)\n",
    "        t.stop()\n",
    "        count = count + 1\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('==== PROCESSING SHARD ' + str(SHARD_ID) + '====')\n",
    "start_processing(INPUT_FOLDER, SHARD_ID, 99999, PERC_TRAIN, PERC_VALIDATE, PERC_TEST, IMAGE_W, IMAGE_H, IMAGE_D, OUTPUT_FOLDER)\n",
    "print('==== ALL DONE ====')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
