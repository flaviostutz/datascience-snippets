{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (50,34,50,1)\n",
    "OUTPUT_DIR = '../../output/train-local/'\n",
    "INPUT_DIR = '../../input/stage1_prepared_some_even/'\n",
    "# LOAD_MODEL_FILE = None\n",
    "LOAD_MODEL_FILE = OUTPUT_DIR + 'tf-checkpoint-best7826'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import *\n",
    "from tflearn.layers.conv import *\n",
    "from tflearn.data_utils import *\n",
    "from tflearn.layers.normalization import *\n",
    "from tflearn.layers.estimator import regression\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import h5py\n",
    "import logging\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.logging\n",
    "import modules.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(input_dir, name, image_dims):\n",
    "    return h5py.File('{}{}-centered-rotated-{}-{}-{}.h5'.format(input_dir,name,image_dims[2],image_dims[1],image_dims[0]), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dirs(output_dir):\n",
    "    logger.info('Preparing output dir')\n",
    "\n",
    "    dir_tflogs = output_dir + 'tf-logs'\n",
    "    dir_checkpoints = output_dir + 'tf-checkpoint'\n",
    "    dir_checkpoint_best = output_dir + 'tf-checkpoint-best'\n",
    "    \n",
    "#     shutil.rmtree(output_dir, True)\n",
    "    try:\n",
    "        os.makedirs(dir_tflogs)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return dir_tflogs, dir_checkpoints, dir_checkpoint_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_test_dataset(input_dir, image_dims):\n",
    "    with load_data(input_dir, 'test', image_dims) as hdf5:\n",
    "        X = hdf5['X']\n",
    "        Y = hdf5['Y']\n",
    "        logger.debug('X_test shape ' + str(X.shape))\n",
    "        logger.debug('Y_test shape ' + str(Y.shape))\n",
    "#         for y in Y:\n",
    "#             print('y=', y)\n",
    "            \n",
    "        logger.info('Evaluate performance on test set...')\n",
    "        acc = model.evaluate(X, Y, batch_size=12)\n",
    "        logger.info('Score on test dataset: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(image_dims):\n",
    "    net = input_data(shape=[None, image_dims[0], image_dims[1], image_dims[2], image_dims[3]], dtype=tf.float32)\n",
    "    \n",
    "    net = conv_3d(net, 32, 3, strides=1, activation='relu')\n",
    "    net = max_pool_3d(net, [1,2,2,2,1], strides=[1,2,2,2,1])\n",
    "\n",
    "    net = conv_3d(net, 64, 3, strides=1, activation='relu')\n",
    "    net = max_pool_3d(net, [1,2,2,2,1], strides=[1,2,2,2,1])\n",
    "    \n",
    "    net = fully_connected(net, 64, activation='relu')\n",
    "    net = dropout(net, 0.8)\n",
    "    \n",
    "    net = fully_connected(net, 2, activation='softmax')\n",
    "    \n",
    "    net = regression(net, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_cnn(output_dir, image_dims):\n",
    "    dir_tflogs, dir_checkpoints, dir_checkpoint_best = prepare_dirs(output_dir)\n",
    "    modules.logging.setup_file_logger(output_dir + 'out.log')\n",
    "\n",
    "    logger.info('Preparing CNN network...')\n",
    "    net = network(image_dims)\n",
    "\n",
    "    logger.info('Preparing DNN trainer...')\n",
    "    model = tflearn.models.dnn.DNN(net, tensorboard_verbose=3, \n",
    "                             tensorboard_dir=dir_tflogs,\n",
    "                             checkpoint_path=dir_checkpoints,\n",
    "                             best_checkpoint_path=dir_checkpoint_best)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_training(model, input_dir, image_dims):\n",
    "\n",
    "    with load_data(input_dir, 'train', image_dims) as train_hdf5:\n",
    "        X = train_hdf5['X']\n",
    "        Y = train_hdf5['Y']\n",
    "        logger.info('X shape ' + str(X.shape))\n",
    "        logger.info('Y shape ' + str(Y.shape))\n",
    "\n",
    "        with load_data(input_dir, 'validate', image_dims) as validate_hdf5:\n",
    "            X_validate = validate_hdf5['X']\n",
    "            Y_validate = validate_hdf5['Y']\n",
    "            logger.info('X_validate shape ' + str(X_validate.shape))\n",
    "            logger.info('Y_validate shape ' + str(Y_validate.shape))\n",
    "\n",
    "            logger.info('Starting CNN training...')\n",
    "            model.fit(X, Y, validation_set=(X_validate, Y_validate), \n",
    "                      shuffle=True, batch_size=10, n_epoch=2,\n",
    "                      show_metric=True, \n",
    "                      run_id='first'+str(image_dims))\n",
    "\n",
    "    evaluate_test_dataset(input_dir, image_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-21 04:45:41,758 INFO PREPARE CNN\n",
      "2017-02-21 04:45:41,760 INFO Preparing output dir\n",
      "2017-02-21 04:45:41,761 INFO Preparing CNN network...\n",
      "2017-02-21 04:45:41,885 INFO Preparing DNN trainer...\n"
     ]
    }
   ],
   "source": [
    "logger.info('PREPARE CNN')\n",
    "model = prepare_cnn(OUTPUT_DIR, IMAGE_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-21 04:45:43,433 INFO LOAD PREVIOUS TRAINING\n",
      "2017-02-21 04:45:44,400 DEBUG X_test shape (111, 50, 34, 50, 1)\n",
      "2017-02-21 04:45:44,401 DEBUG Y_test shape (111, 2)\n",
      "2017-02-21 04:45:44,447 INFO Evaluate performance on test set...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 0.  1.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 0.  1.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 0.  1.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 0.  1.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 1.  0.]\n",
      "y= [ 0.  1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-21 04:46:34,812 INFO Score on test dataset: [0.95495495119610352]\n"
     ]
    }
   ],
   "source": [
    "if(LOAD_MODEL_FILE is not None):\n",
    "    logger.info('LOAD PREVIOUS TRAINING')\n",
    "    model.load(LOAD_MODEL_FILE)\n",
    "    evaluate_test_dataset(INPUT_DIR, IMAGE_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logger.info('TRAIN CNN')\n",
    "# start_training(model, INPUT_DIR, IMAGE_DIMS)\n",
    "# model.save(OUTPUT_DIR + 'final')\n",
    "# logger.info('==== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
