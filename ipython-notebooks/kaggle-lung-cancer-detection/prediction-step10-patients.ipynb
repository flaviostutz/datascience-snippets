{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (50, 34, 50, 1)\n",
    "\n",
    "SAVE_IMAGES = True\n",
    "\n",
    "INPUT_FOLDER = '../../input/sample_images/'\n",
    "OUTPUT_FOLDER = '../../output/step10/'\n",
    "\n",
    "PATIENTS_FILE = '../../input/sample_dummy_submission.csv'\n",
    "CNN_MODEL_FILE = '../../output/train-local/tf-checkpoint-best7826'\n",
    "\n",
    "_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import h5py\n",
    "from random import shuffle\n",
    "import numpy as np # linear algebra\n",
    "from numpy import ndarray\n",
    "import statistics\n",
    "import csv\n",
    "import dicom\n",
    "import math\n",
    "from time import time\n",
    "import os\n",
    "import shutil\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "from skimage import measure, morphology, transform\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import logging\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import *\n",
    "from tflearn.layers.conv import *\n",
    "from tflearn.data_utils import *\n",
    "from tflearn.layers.normalization import *\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.logging\n",
    "import modules.lungprepare as lungprepare\n",
    "import modules.utils as utils\n",
    "from modules.utils import Timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_patient_ids(patients_file):\n",
    "    patients = []\n",
    "    \n",
    "    file = csv.DictReader(open(patients_file))\n",
    "    for row in file:\n",
    "        p = row['id']\n",
    "        patients.append(p)\n",
    "    logger.info('found {} patients for prediction'.format(len(patients)))\n",
    "    \n",
    "    return patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(image_dims):\n",
    "    net = input_data(shape=[None, image_dims[0], image_dims[1], image_dims[2], image_dims[3]], dtype=tf.float32)\n",
    "    \n",
    "    net = conv_3d(net, 32, 3, strides=1, activation='relu')\n",
    "    net = max_pool_3d(net, [1,2,2,2,1], strides=[1,2,2,2,1])\n",
    "\n",
    "    net = conv_3d(net, 64, 3, strides=1, activation='relu')\n",
    "    net = max_pool_3d(net, [1,2,2,2,1], strides=[1,2,2,2,1])\n",
    "    \n",
    "    net = fully_connected(net, 64, activation='relu')\n",
    "    net = dropout(net, 0.8)\n",
    "    \n",
    "    net = fully_connected(net, 2, activation='softmax')\n",
    "    \n",
    "    net = regression(net, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_cnn(cnn_model_file, image_dims):\n",
    "    global _model\n",
    "    if(_model is None):\n",
    "        logger.info('Prepare CNN')\n",
    "\n",
    "        logger.info('Load CNN network...')\n",
    "        net = network(image_dims)\n",
    "\n",
    "        logger.info('Start engine...')\n",
    "        _model = tflearn.models.dnn.DNN(net)\n",
    "\n",
    "        logger.info('Load previous training...')\n",
    "        _model.load(cnn_model_file)\n",
    "    else:\n",
    "        logger.info('CNN model already loaded. Reusing.')\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_patient(model, input_dir, patient_id, image_dims, output_dir):\n",
    "    logger.info('>>> Predict patient_id ' + patient_id)\n",
    "    logger.info('Loading pre-processed images for patient')\n",
    "\n",
    "    dataset_file = output_dir + 'predict-centered-rotated-{}-{}-{}.h5'.format(image_dims[0], image_dims[1], image_dims[2])\n",
    "    \n",
    "    #patient pre-processed image cache\n",
    "    patient_pixels = None\n",
    "    with h5py.File(dataset_file, 'a') as h5f:\n",
    "        try:\n",
    "            patient_pixels = h5f[patient_id]\n",
    "            logger.debug('Patient image found in cache. Using it.')\n",
    "            #disconnect from HDF5\n",
    "            patient_pixels = np.array(patient_pixels)\n",
    "            \n",
    "        except KeyError:\n",
    "            logger.debug('Patient image not found in cache')\n",
    "            t = Timer('Preparing patient scan image volume. patient_id=' + patient_id)\n",
    "            patient_pixels = lungprepare.process_patient_images(input_dir + patient_id, image_dims)\n",
    "            if(patient_pixels is None):\n",
    "                logger.warning('Patient lung not found. Skipping.')\n",
    "            logger.debug('Storing patient image in cache')\n",
    "            h5f[patient_id] = patient_pixels\n",
    "            t.stop()\n",
    "    \n",
    "    t = Timer('Predicting result on CNN (forward)')\n",
    "    y = model.predict(np.expand_dims(patient_pixels, axis=0))\n",
    "    logger.info('PATIENT '+ patient_id +' PREDICT=' + str(y))\n",
    "    utils.show_slices(patient_pixels, patient_id)\n",
    "    t.stop()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_processing(input_dir, patients_file, cnn_model_file, max_patients, image_dims, output_dir):\n",
    "    logger.info('Predicting patients. ' + ' max_patients='+ str(max_patients) + ' input_dir=' + input_dir + ' output_dir=' + output_dir)\n",
    "    \n",
    "    logger.info('Preparing output dir')\n",
    "#     shutil.rmtree(output_dir, True)\n",
    "    try:\n",
    "        os.makedirs(output_dir + 'images/')\n",
    "    except:\n",
    "        logger.warning('Ops! Couldnt create output dir')\n",
    "        pass\n",
    "\n",
    "    modules.logging.setup_file_logger(output_dir + 'out.log')\n",
    "\n",
    "    model = prepare_cnn(cnn_model_file, image_dims)\n",
    "    \n",
    "    logger.info('Collect patient ids for analysis')\n",
    "    patient_ids = get_patient_ids(patients_file)\n",
    "    total_patients = len(patient_ids)\n",
    "    logger.debug('Found ' + str(total_patients) + ' patients')\n",
    "\n",
    "    count = 0\n",
    "    for patient_id in patient_ids:\n",
    "        if(count>(max_patients-1)):\n",
    "            break\n",
    "            \n",
    "        y = predict_patient(model, input_dir, patient_id, image_dims, output_dir)\n",
    "        logger.info(\"Prediction for patient \" + patient_id + ' is ' + str(y))\n",
    "\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-21 04:15:26,986 INFO ==== PROCESSING PREDICTION ====\n",
      "2017-02-21 04:15:26,988 INFO Predicting patients.  max_patients=9 input_dir=../../input/sample_images/ output_dir=../../output/step10/\n",
      "2017-02-21 04:15:26,989 INFO Preparing output dir\n",
      "2017-02-21 04:15:26,990 WARNING Ops! Couldnt create output dir\n",
      "2017-02-21 04:15:26,992 INFO CNN model already loaded. Reusing.\n",
      "2017-02-21 04:15:26,993 INFO Collect patient ids for analysis\n",
      "2017-02-21 04:15:26,994 INFO found 19 patients for prediction\n",
      "2017-02-21 04:15:26,995 DEBUG Found 19 patients\n",
      "2017-02-21 04:15:26,996 INFO >>> Predict patient_id 0de72529c30fe642bc60dcb75c87f6bd\n",
      "2017-02-21 04:15:26,997 INFO Loading pre-processed images for patient\n",
      "2017-02-21 04:15:27,000 DEBUG Patient image found in cache. Using it.\n",
      "2017-02-21 04:15:27,005 INFO > [started] Predicting result on CNN (forward)...\n",
      "2017-02-21 04:15:27,937 INFO PATIENT 0de72529c30fe642bc60dcb75c87f6bd PREDICT=[[0.904554009437561, 0.095445916056633]]\n"
     ]
    }
   ],
   "source": [
    "logger.info('==== PROCESSING PREDICTION ====')\n",
    "start_processing(INPUT_FOLDER, PATIENTS_FILE, CNN_MODEL_FILE, 9, IMAGE_DIMS, OUTPUT_FOLDER)\n",
    "logger.info('==== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
