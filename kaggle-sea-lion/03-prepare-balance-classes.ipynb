{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyse and balance classes from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INPUT_DIR='../../input/kaggle-sea-lion/02/'\n",
    "OUTPUT_DIR='../../output/kaggle-sea-lion/03/'\n",
    "\n",
    "SHOW_IMAGES = True\n",
    "MAX_IMAGES = 3\n",
    "\n",
    "IMAGE_DIMS = (148,148,3)\n",
    "\n",
    "#%prun print('test')\n",
    "#%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import modules.logging\n",
    "from modules.logging import logger\n",
    "import modules.lions as lions\n",
    "from modules.utils import Timer\n",
    "import modules.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 03:48:13,719 INFO Dir ../../output/kaggle-sea-lion/03/ created\n"
     ]
    }
   ],
   "source": [
    "utils.mkdirs(OUTPUT_DIR, recreate=True)\n",
    "modules.logging.setup_file_logger(OUTPUT_DIR + 'out.log')\n",
    "logger.info('Dir ' + OUTPUT_DIR + ' created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Rebalance dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#max_augmentation_rotation=20, max_augmentation_shift=0, max_augmentation_scale=1, augmentation_flip_leftright=True, augmentation_flip_updown=True\n",
    "def dataset_xy_balance_classes_image(input_h5file_path, output_h5file_path, max_augmentation_ratio=3, max_undersampling_ratio=0):\n",
    "    if(os.path.isfile(output_h5file_path)):\n",
    "        raise Exception('Output file already exists. file=' + output_h5file_path)\n",
    "    \n",
    "    logger.info('loading input dataset ' + input_h5file_path)\n",
    "    input_h5 = h5py.File(input_h5file_path, 'r')\n",
    "    input_x_ds = input_h5['X'][0:5]\n",
    "    input_y_ds = input_h5['Y'][0:5]\n",
    "    x_dims = input_x_ds.shape\n",
    "    y_dims = input_y_ds.shape\n",
    "\n",
    "    nr_classes = input_y_ds.shape[1]\n",
    "\n",
    "    t = Timer('traversing entire dataset in order to extract population classes distribution')\n",
    "    count_classes = np.zeros(nr_classes)\n",
    "    for y in input_y_ds:\n",
    "        #convert from categorical to label\n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        lb.fit(np.array(range(nr_classes)))\n",
    "        Y_label = lb.inverse_transform(Y)\n",
    "        \n",
    "        count_classes[Y_label] = count_classes[Y_label] + 1\n",
    "    t.stop()\n",
    "\n",
    "    logger.info('population distribution')\n",
    "    smallest_class = None\n",
    "    smallest_qtty = 999999999\n",
    "    largest_class = None\n",
    "    largest_qtty = 0\n",
    "    for i,c in enumerate(count_classes):\n",
    "        logger.info(str(i) + ': ' + str(c))\n",
    "        if(c<smallest_qtty):\n",
    "            smallest_qtty = c\n",
    "            smallest_class = i\n",
    "        if(c>largest_qtty):\n",
    "            largest_qtty = c\n",
    "            largest_class = i\n",
    "    \n",
    "    qtty_per_class = min(smallest_qtty*max_augmentation_ratio, largest_qtty)\n",
    "    logger.info('items per class: ' + str(qtty_per_class))\n",
    "    \n",
    "    logger.info('augmentation/undersampling ratio per class')\n",
    "    ratio_classes = np.zeros(nr_classes)\n",
    "    for i,c in enumerate(count_classes):\n",
    "        ratio_classes[i] = qtty_per_class/c\n",
    "        logger.info(str(i) + ': ' + str(ratio_classes[i]))\n",
    "    \n",
    "    logger.info('creating output dataset ' + output_h5file_path)\n",
    "    output_h5 = h5py.File(output_h5file_path, 'w')\n",
    "    x_dims_zero = x_dims.copy()\n",
    "    x_dims_zero[0] = 0\n",
    "    x_dims_one = x_dims.copy()\n",
    "    x_dims_one[0] = 1\n",
    "    x_dims_none = x_dims.copy()\n",
    "    x_dims_none[0] = None\n",
    "    output_x_ds = output_h5.create_dataset('X', x_dims_zero, maxshape=x_dims_none, chunks=x_dims_one, dtype='f')\n",
    "    output_y_ds = output_h5.create_dataset('Y', y_dims_zero, maxshape=y_dims_none, dtype='f')\n",
    "    \n",
    "    #TODO: NOW ITERATE OVER INPUT AND AUGMENT/UNDERSAMPLE ITEMS ACCORDING TO RATIO_CLASSES!\n",
    "    parei aqui\n",
    "    \n",
    "    logger.info('done')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-03 03:48:16,126 INFO loading input dataset ../../input/kaggle-sea-lion/02/lion-patches-full-148-148.h5\n",
      "2017-04-03 03:48:16,130 INFO > [started] traversing entire dataset in order to extract population classes distribution...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'item' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-41803442808f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_h5file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lion-patches'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_DIMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset_xy_balance_classes_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_h5file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_h5file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_augmentation_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_undersampling_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ec6a19d49c84>\u001b[0m in \u001b[0;36mdataset_xy_balance_classes_image\u001b[0;34m(input_h5file_path, output_h5file_path, max_augmentation_ratio, max_undersampling_ratio)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcount_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_x_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_y_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'item' is not defined"
     ]
    }
   ],
   "source": [
    "input_h5file_path = INPUT_DIR + utils.dataset_name('lion-patches-full', IMAGE_DIMS)\n",
    "output_h5file_path = OUTPUT_DIR + utils.dataset_name('lion-patches', IMAGE_DIMS)\n",
    "\n",
    "dataset_xy_balance_classes_image(input_h5file_path, output_h5file_path, max_augmentation_ratio=3, max_undersampling_ratio=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Validate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
