{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate competition submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../../input/kaggle-sea-lion/'\n",
    "OUTPUT_DIR = '../../output/kaggle-sea-lion/20/'\n",
    "\n",
    "IMAGE_DIMS = (42,42,3)\n",
    "LABEL_DIMS = (6,)\n",
    "LOAD_WEIGHTS_FILE = INPUT_DIR + '05/weights-medium1-42x42-0.94.h5'\n",
    "LOAD_MODEL_FILE = None\n",
    "DEBUG = True\n",
    "#IMAGE_SLICE = slice(1400,1800)\n",
    "IMAGE_SLICE = slice(0,99999)\n",
    "\n",
    "NR_SHARDS = 4\n",
    "RECREATE_OUTPUT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.utils as utils\n",
    "from modules.utils import Timer\n",
    "import modules.logging as logging\n",
    "import modules.cnn as cnn\n",
    "import modules.lions as lions\n",
    "import modules.shards as shards\n",
    "import modules.objectdetect as objectdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classify and count lions on each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Find lions on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from MismatchedTrainImages.txt\n",
    "MISMATCHED = [3, 7, 9, 21, 30, 34, 71, 81, 89, 97, 151, 184, 215, 234, 242, 268, 290, 311, 331, 344, 380, 384, 406, 421, 469, 475, 490, 499, 507, 530, 531, 605, 607, 614, 621, 638, 644, 687, 712, 721, 767, 779, 781, 794, 800, 811, 839, 840, 869, 882, 901, 903, 905, 909, 913, 927, 946]\n",
    "FORCE_IMAGES = [42]\n",
    "FORCE_IMAGES = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_shard_lions(shard_group, shard_id):\n",
    "    t = Timer('PROCESSING SHARD {}'.format(shard_id))\n",
    "\n",
    "    output_dir = shard_group.shard_dir(shard_id)\n",
    "    logging.setup_file_logger(output_dir + 'out.log')\n",
    "    \n",
    "    logger.info('Load CNN model')\n",
    "    #lion simple cnn forward time: ~10ms\n",
    "    print(LOAD_WEIGHTS_FILE)\n",
    "    model = lions.convnet_medium1_lion_keras(IMAGE_DIMS)\n",
    "    model.load_weights(LOAD_WEIGHTS_FILE)    \n",
    "\n",
    "    #DECLARE FUNCTIONS INSIDE PROCESS INSTANCE\n",
    "    \"\"\" Returns (score, label) \"\"\"\n",
    "    def evaluate_region_all_classes(region_img):\n",
    "        y_pred = model.predict(np.array([region_img]))\n",
    "        ylp = utils.onehot_to_label(np.array(y_pred))\n",
    "        return y_pred[0][ylp[0]], ylp[0]\n",
    "\n",
    "    \n",
    "    def detect_lions(image, evaluate_function):\n",
    "        #search for lions\n",
    "        region_generator = objectdetect.sliding_window_generator(image, step=(19,19), window=IMAGE_DIMS, pyramid_max_layers=1)\n",
    "        detections, imgs = objectdetect.evaluate_regions(region_generator, evaluate_function, filter_score_min=0.97, \n",
    "                                                         filter_labels=(0,1,2,3,4), apply_non_max_suppression=True, \n",
    "                                                         supression_overlap_threshold=0.1, threads=None)\n",
    "        #calculate detection class distribution\n",
    "        detected_lions = np.zeros(LABEL_DIMS[0]-1, dtype='int')\n",
    "        for detection in detections:\n",
    "            label = int(detection[5])\n",
    "            detected_lions[label] += 1 \n",
    "\n",
    "        if(DEBUG):\n",
    "            def detection_to_colortext(detection):\n",
    "                score = detection[4]\n",
    "                text = str(int(detection[5])) + ' ' + '{0:.2f}'.format(score)\n",
    "                c = int(score*255)\n",
    "                return (0,0,c), text\n",
    "\n",
    "            img2 = image.copy()\n",
    "            objectdetect.draw_detections(detections, img2, detection_to_colortext)\n",
    "            utils.show_image(img2, size=60, is_bgr=True)\n",
    "    #        patches = objectdetect.extract_patches(detections, img)\n",
    "    #        utils.show_images(patches[0:50], size=2, cols=10, is_bgr=True)   \n",
    "\n",
    "        return detected_lions.tolist()\n",
    "\n",
    "    if(shard_group.shard_done(shard_id)):\n",
    "        logger.warning('shard {} already processed. Skipping'.format(shard_id))\n",
    "\n",
    "    else:\n",
    "        image_paths = shard_group.shard_items(shard_id)\n",
    "\n",
    "        total_detected_lions = []\n",
    "\n",
    "        for image_path in image_paths:\n",
    "            base = os.path.basename(image_path)\n",
    "            fn = os.path.splitext(base)\n",
    "            if(fn[1]!='.jpg'):\n",
    "                logger.info('ignoring non jpg image. filename=' + base)\n",
    "                continue\n",
    "\n",
    "            train_id = int(fn[0])\n",
    "\n",
    "            if(FORCE_IMAGES!=None and train_id not in FORCE_IMAGES):\n",
    "                continue\n",
    "\n",
    "            t = Timer('processing photo ' + image_path)\n",
    "            image_raw = cv2.imread(image_path)\n",
    "            image_raw = image_raw[IMAGE_SLICE]\n",
    "            detected_lions = detect_lions(image_raw, evaluate_region_all_classes)\n",
    "            logger.info('image ' + str(train_id))\n",
    "            logger.info('total detections: ' + str(np.sum(np.array(detected_lions))))\n",
    "            logger.info('class detections: ' + str(detected_lions))\n",
    "            total_detected_lions += [[train_id] + detected_lions]\n",
    "            t.stop()\n",
    "\n",
    "        logger.info('GENERATE SUBMISSION FILE')\n",
    "        submission_file = output_dir + 'submission.csv'\n",
    "        df = pd.DataFrame(total_detected_lions, columns=('test_id','adult_males','subadult_males','adult_females','juveniles','pups'))\n",
    "        df.to_csv(submission_file, index=False)\n",
    "\n",
    "        logger.info('detection result exported to ' + submission_file)        \n",
    "        shard_group.mark_done(shard_id)\n",
    "\n",
    "        t.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-05 02:52:38,562 INFO ==== PROCESSING SHARDS IN PARALLEL ====\n",
      "2017-06-05 02:52:38,564 INFO preparing shards\n"
     ]
    }
   ],
   "source": [
    "logging.setup_file_logger(OUTPUT_DIR + 'out.log')\n",
    "logger.info('==== PROCESSING SHARDS IN PARALLEL ====')\n",
    "\n",
    "logger.info('preparing shards')\n",
    "images_dir = INPUT_DIR + \"Train/\"\n",
    "image_paths = [images_dir+n for n in os.listdir(images_dir)]\n",
    "\n",
    "shard_group = shards.ShardGroup(image_paths, NR_SHARDS, OUTPUT_DIR, recreate_shards_dir=RECREATE_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-05 02:52:38,589 INFO Using 4 parallel tasks\n",
      "2017-06-05 02:52:40,620 INFO > [started] PROCESSING SHARD 4...\n",
      "2017-06-05 02:52:40,629 INFO Load CNN model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../input/kaggle-sea-lion/05/weights-medium1-42x42-0.94.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(64, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(128, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(256, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:78: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:80: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:82: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, kernel_initializer=\"glorot_uniform\", activation=\"softmax\")`\n",
      "  model.add(core.Dense(6, activation='softmax', init='glorot_uniform'))\n",
      "2017-06-05 02:52:41,057 WARNING shard 4 already processed. Skipping\n",
      "2017-06-05 02:52:42,622 INFO > [started] PROCESSING SHARD 2...\n",
      "2017-06-05 02:52:42,629 INFO Load CNN model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../input/kaggle-sea-lion/05/weights-medium1-42x42-0.94.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(64, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(128, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(256, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:78: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:80: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:82: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, kernel_initializer=\"glorot_uniform\", activation=\"softmax\")`\n",
      "  model.add(core.Dense(6, activation='softmax', init='glorot_uniform'))\n",
      "2017-06-05 02:52:43,040 WARNING shard 2 already processed. Skipping\n",
      "2017-06-05 02:52:44,624 INFO > [started] PROCESSING SHARD 3...\n",
      "2017-06-05 02:52:44,634 INFO Load CNN model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../input/kaggle-sea-lion/05/weights-medium1-42x42-0.94.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(64, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(128, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(256, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:78: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:80: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:82: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, kernel_initializer=\"glorot_uniform\", activation=\"softmax\")`\n",
      "  model.add(core.Dense(6, activation='softmax', init='glorot_uniform'))\n",
      "2017-06-05 02:52:45,028 WARNING shard 3 already processed. Skipping\n",
      "2017-06-05 02:52:46,625 INFO > [started] PROCESSING SHARD 1...\n",
      "2017-06-05 02:52:46,631 INFO Load CNN model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../input/kaggle-sea-lion/05/weights-medium1-42x42-0.94.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(64, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(128, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(convolutional.Conv2D(256, (3, 3), activation='relu', padding='same', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:78: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:80: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_initializer=\"glorot_uniform\", activation=\"relu\")`\n",
      "  model.add(core.Dense(1024, activation='relu', init='glorot_uniform'))\n",
      "/notebooks/datascience-snippets/kaggle-sea-lion/modules/lions.py:82: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, kernel_initializer=\"glorot_uniform\", activation=\"softmax\")`\n",
      "  model.add(core.Dense(6, activation='softmax', init='glorot_uniform'))\n",
      "2017-06-05 02:52:47,054 WARNING shard 1 already processed. Skipping\n",
      "2017-06-05 02:52:47,111 INFO ==== ALL DONE ====\n"
     ]
    }
   ],
   "source": [
    "shard_group.start_processing(process_shard_lions, shard_ids=None)\n",
    "logger.info('==== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Combine all shard results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-05 03:11:00,951 INFO COMBINING ALL SHARD RESULTS INTO ONE SUBMISSION FILE\n",
      "2017-06-05 03:11:00,976 INFO submission file merged\n"
     ]
    }
   ],
   "source": [
    "logger.info('COMBINING ALL SHARD RESULTS INTO ONE SUBMISSION FILE')\n",
    "\n",
    "total_detected_lions = np.array([])\n",
    "for sd in shard_group.shard_dirs():\n",
    "    df = pd.read_csv(sd + 'submission.csv')\n",
    "    if(len(total_detected_lions)>0):\n",
    "        total_detected_lions = np.concatenate((total_detected_lions, df.as_matrix()))\n",
    "    else:\n",
    "        total_detected_lions = df.as_matrix()\n",
    "\n",
    "submission_file = OUTPUT_DIR + 'submission-merged.csv'\n",
    "df = pd.DataFrame(total_detected_lions, columns=('test_id','adult_males','subadult_males','adult_females','juveniles','pups'))\n",
    "df = df.sort_values('test_id')\n",
    "df.to_csv(submission_file, index=False)\n",
    "logger.info('submission file merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
