{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train sea lion classifier with a convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../../input/kaggle-sea-lion/03/'\n",
    "OUTPUT_DIR = '../../output/kaggle-sea-lion/05/'\n",
    "IMAGE_DIMS = (84,84,3)\n",
    "\n",
    "INPUT_DATASET_NAME = 'lion-patches-0px-balanced'\n",
    "LOAD_WEIGHTS_FILE = OUTPUT_DIR + 'last-weights.h5'\n",
    "SAVE_WEIGHTS_FILE = LOAD_WEIGHTS_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from modules.logging import logger\n",
    "import modules.utils as utils\n",
    "from modules.utils import Timer\n",
    "import modules.logging\n",
    "import modules.cnn as cnn\n",
    "import modules.lions as lions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "utils.mkdirs(OUTPUT_DIR, dirs=['tf-logs','weights'], recreate=False)\n",
    "modules.logging.setup_file_logger(OUTPUT_DIR + 'out.log')\n",
    "tf_logs_dir = OUTPUT_DIR + '/tf-logs/'\n",
    "weights_file = OUTPUT_DIR + 'weights-{epoch:02d}-{val_acc:.2f}.h5'\n",
    "input_dataset_path = INPUT_DIR + utils.dataset_name(INPUT_DATASET_NAME, IMAGE_DIMS)\n",
    "\n",
    "logger.info('Output dirs created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger.info('Load CNN model for training')\n",
    "model = lions.convnet_alexnet_lion_keras(IMAGE_DIMS)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger.info('Using dataset ' + input_dataset_path + ' as input')\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=True,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=360,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)\n",
    "\n",
    "logger.info('loading input data')\n",
    "#X_train,Y_train = utils.dataset_xy_hdf5matrix_keras(input_dataset_path, 0, 0.8)\n",
    "#X_validation,Y_validation = utils.dataset_xy_hdf5matrix_keras(input_dataset_path, 0.8, 0.9)\n",
    "#logger.info('X shape ' + str(X_train.shape))\n",
    "#logger.info('Y shape ' + str(Y_train.shape))\n",
    "\n",
    "if(os.path.isfile(LOAD_WEIGHTS_FILE)):\n",
    "    logger.info('Loading previous weights...')\n",
    "    model.load_weights(WEIGHTS_FILE)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=tf_logs_dir, histogram_freq=0, write_graph=True, write_images=True)\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(weights_file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "progbar_callback = keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "\n",
    "logger.info('Starting CNN training...')\n",
    "\n",
    "with h5py.File(input_dataset_path, 'r') as h5file:\n",
    "    train_batch_generator = utils.batch_generator_xy_h5(h5file, start_ratio=0, end_ratio=0.8, batch_size=32)\n",
    "    train_generator = utils.image_batch_xy(train_batch_generator, image_generator)\n",
    "    train_epoch_size = utils.dataset_size_h5(h5file, start_ratio=0, end_ratio=0.8)\n",
    "\n",
    "    validate_generator = utils.batch_generator_xy_h5(h5file, start_ratio=0.8, end_ratio=0.9, batch_size=32)\n",
    "    validate_size = utils.dataset_size_h5(h5file, start_ratio=0.8, end_ratio=0.9)\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                  samples_per_epoch = train_epoch_size,\n",
    "                  nb_epoch = 1, \n",
    "                  callbacks = [tensorboard_callback, checkpoint_callback, progbar_callback],\n",
    "                  validation_data = validate_generator, \n",
    "                  validation_steps = validate_size,\n",
    "                  verbose = 1)\n",
    "\n",
    "    if(SAVE_WEIGHTS_FILE!=None):\n",
    "        logger.info('Saving last weights...')\n",
    "        model.save_weights(SAVE_WEIGHTS_FILE)\n",
    "\n",
    "    cnn.show_training_info_keras(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger.info('Evaluate dataset')\n",
    "dataset_path = INPUT_DIR + utils.dataset_name('lion-patches', IMAGE_DIMS)\n",
    "\n",
    "X_test,Y_test = utils.dataset_xy_hdf5matrix_keras(input_dataset_path, 0.9, 1)\n",
    "cnn.evaluate_dataset_keras(X_test, Y_test, model, batch_size=24, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with h5py.File(input_dataset_path, 'r') as h5file:\n",
    "#     batch_generator = batch_generator_xy_h5(h5file, start_ratio=0, end_ratio=1, batch_size=4, x_dataset='X', y_dataset='Y')\n",
    "#     train_generator = image_batch_xy(batch_generator, image_data_generator)\n",
    "#     counter = 0\n",
    "#     for x, y in train_generator:\n",
    "#         print(y)\n",
    "#         utils.show_images(x)\n",
    "#         counter += 1\n",
    "#         if(counter>30): \n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
